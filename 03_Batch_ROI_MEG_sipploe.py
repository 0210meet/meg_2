import os
import mne
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
# from run_thal_cortex_spike_ccg_strong import run_bidirectional_spike_ccg
from SEEG_Cortex_Thalamus_CCG_Analysis import run_spike_propagation_analysis
# from strong import run_single_run_strong
from scipy.signal import correlate
from scipy.stats import zscore
from scipy.stats import bootstrap
from scipy.stats import gaussian_kde

# ===================== 0. å…¨å±€é…ç½®ä¸å‰ç½®ä¿®å¤ =====================
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# 1. æ‰¹é‡æ ¸å¿ƒé…ç½®
SUBJECTS = [f"sub-{i:02d}" for i in range(1, 9)]  # sub-01 ~ sub-08
# SUBJECTS = ["sub-01"]  # æµ‹è¯•æ—¶å¯å•ç‹¬æŒ‡å®šè¢«è¯•
STATES = ["EC", "EO"]  # å®éªŒçŠ¶æ€ï¼šé—­çœ¼/ççœ¼

# 2. è·¯å¾„é…ç½®ï¼ˆä¸é€†è§£ä»£ç å®Œå…¨å¯¹é½ï¼‰
SOURCE_DIR = "/data/shared_home/tlm/Project/MEG-C/source"  # STCæ–‡ä»¶ä¿å­˜ç›®å½•
FREESURFER_DIR = "/data/shared_home/tlm/data/MEG-C/freesurfer/mri"  # Freesurferè§£å‰–æ•°æ®ç›®å½•
SAVE_DIR = "/data/shared_home/tlm/Project/MEG-C/results4"  # CCGç»“æœä¿å­˜ç›®å½•
os.makedirs(SAVE_DIR, exist_ok=True)

# 3. ä¸˜è„‘æºç©ºé—´ç´¢å¼•æ˜ å°„
THAL_SRC_MAP = {
    "left": {"src_idx": 2, "name": "Left-Thalamus-Proper", "hemi": "lh"},
    "right": {"src_idx": 3, "name": "Right-Thalamus-Proper", "hemi": "rh"}
}


# ===================== å·¥å…·å‡½æ•°ï¼ˆæ•´åˆä¼˜åŒ–ï¼‰ =====================
def check_path(path, path_type="file"):
    """æ£€æŸ¥æ–‡ä»¶/ç›®å½•æ˜¯å¦å­˜åœ¨ï¼ˆåŒºåˆ†ç±»å‹ï¼‰"""
    if path_type == "file":
        return os.path.isfile(path)
    elif path_type == "dir":
        return os.path.isdir(path)
    return False


def find_stc_file(run_path, subject, run, state):
    """æ¨¡ç³ŠåŒ¹é…STCæ–‡ä»¶ï¼ˆé€‚é…ä¸åŒå‘½ååç¼€ï¼‰"""
    for fname in os.listdir(run_path):
        if fname.endswith(".h5") and all([x in fname for x in [subject, run, state]]):
            return os.path.join(run_path, fname)
    return None


def build_vertno_map(src):
    """æ„å»ºå…¨å±€é¡¶ç‚¹å· â†’ stc.dataå±€éƒ¨ç´¢å¼•çš„æ˜ å°„è¡¨"""
    vertno_map = {}
    local_idx = 0
    for s in src:
        for vert in s["vertno"]:
            vertno_map[vert] = local_idx
            local_idx += 1
    return vertno_map


def find_most_active_dipole(roi_verts_local, stc_data):
    """æ‰¾åˆ°ROIå†…å¹…å€¼æœ€å¤§çš„å•ä¸ªå¶æå­"""
    if len(roi_verts_local) == 0:
        print("âš ï¸ ROIæ— æœ‰æ•ˆå¶æå­ï¼")
        return -1, 0, np.zeros(stc_data.shape[1])

    roi_ts = stc_data[roi_verts_local, :]
    dipole_activity = np.max(np.abs(roi_ts), axis=1)
    max_idx_in_roi = np.argmax(dipole_activity)
    dipole_idx_local = roi_verts_local[max_idx_in_roi]
    dipole_max_amp = dipole_activity[max_idx_in_roi]
    dipole_ts = stc_data[dipole_idx_local, :]
    return dipole_idx_local, dipole_max_amp, dipole_ts


def process_single_case(subject, run, state, src):
    """
    å¤„ç†å•ä¸ªè¢«è¯•-å•ä¸ªrun-å•ä¸ªçŠ¶æ€ï¼ˆå¤ç”¨å·²åŠ è½½çš„srcï¼‰
    è¿”å›ï¼šTrue/Falseï¼ˆæˆåŠŸ/å¤±è´¥ï¼‰
    """
    try:
        # 1. å®šä½STCæ–‡ä»¶
        run_path = os.path.join(SOURCE_DIR, subject, run)
        stc_fname = find_stc_file(run_path, subject, run, state)
        if not stc_fname or not check_path(stc_fname):
            print(f"âŒ {subject}-{run}-{state}ï¼šSTCæ–‡ä»¶ç¼ºå¤± â†’ è·³è¿‡")
            return False

        # 2. è¯»å–STCæ•°æ®
        stc = mne.read_source_estimate(stc_fname)
        times = stc.times
        sfreq = 1 / (times[1] - times[0])
        vertno_map = build_vertno_map(src)
        print(f"âœ… {subject}-{run}-{state}ï¼šæ•°æ®åŠ è½½å®Œæˆ | é‡‡æ ·é¢‘ç‡ï¼š{sfreq:.1f}Hz")

        # 3. æå–çš®å±‚ROIï¼ˆaparcåˆ†åŒºï¼‰
        labels_cortex = mne.read_labels_from_annot(subject, parc="aparc", subjects_dir=FREESURFER_DIR)
        label_ts_cortex = mne.extract_label_time_course(
            [stc], labels_cortex, src, mode="mean", allow_empty=True
        )[0]
        label_ts_cortex = np.asarray(label_ts_cortex)

        # 4. ç­›é€‰æœ€æ´»è·ƒçš„çš®å±‚ROI
        roi_info_cortex = [{
            'roi_idx': idx,
            'name': label.name,
            'verts_local': [vertno_map[v] for v in label.vertices if v in vertno_map],
            'max_activity': np.abs(label_ts_cortex[idx]).max()
        } for idx, label in enumerate(labels_cortex)]
        roi_info_cortex.sort(key=lambda x: x["max_activity"], reverse=True)
        most_active_cortex = roi_info_cortex[0]
        cortex_side = "left" if "lh" in most_active_cortex["name"] else "right"
        print(f"ğŸ† {subject}-{run}-{state}ï¼šæœ€æ´»è·ƒçš®å±‚ROI â†’ {most_active_cortex['name']}ï¼ˆ{cortex_side}åŠçƒï¼‰")

        # 5. æ„å»ºåŒä¾§ä¸˜è„‘ROI
        thal_config = THAL_SRC_MAP[cortex_side]
        thal_verts_global = src[thal_config["src_idx"]]["vertno"]
        thal_verts_local = [vertno_map[v] for v in thal_verts_global if v in vertno_map]
        if len(thal_verts_local) == 0:
            print(f"âŒ {subject}-{run}-{state}ï¼šä¸˜è„‘æ— æœ‰æ•ˆå¶æå­ â†’ è·³è¿‡")
            return False

        thal_label = mne.Label(vertices=thal_verts_global, hemi=thal_config["hemi"], name=thal_config["name"],
                               subject=subject)
        label_ts_thal = mne.extract_label_time_course([stc], [thal_label], src, mode="mean", allow_empty=True)[0][0]

        # 6. æ‰¾æœ€æ´»è·ƒå¶æå­
        cortex_dipole_idx, cortex_dipole_amp, cortex_dipole_ts = find_most_active_dipole(
            most_active_cortex["verts_local"], stc.data
        )
        thal_dipole_idx, thal_dipole_amp, thal_dipole_ts = find_most_active_dipole(
            thal_verts_local, stc.data
        )
        print(
            f"âš¡ {subject}-{run}-{state}ï¼šæ ¸å¿ƒå¶æå­ | çš®å±‚å¹…å€¼ï¼š{cortex_dipole_amp:.2f}nAm | ä¸˜è„‘å¹…å€¼ï¼š{thal_dipole_amp:.2f}nAm")

        # 7. è¿è¡ŒCCGåˆ†æå¹¶ä¿å­˜ç»“æœ
        tag = f"{subject}_{run}_{state}"
        case_save_dir = os.path.join(SAVE_DIR, subject, run, state)
        os.makedirs(case_save_dir, exist_ok=True)
        ccg_results = run_spike_propagation_analysis(cortex_dipole_ts, thal_dipole_ts, sfreq, tag=tag, save_dir=case_save_dir)
        np.save(os.path.join(case_save_dir, f"{tag}_ccg_results.npy"), ccg_results)
        print(f"ğŸ’¾ {subject}-{run}-{state}ï¼šç»“æœä¿å­˜è‡³ {case_save_dir}")

        # é‡Šæ”¾å†…å­˜
        del stc, label_ts_cortex, cortex_dipole_ts, thal_dipole_ts, ccg_results
        return True

    except Exception as e:
        print(f"âŒ {subject}-{run}-{state}ï¼šå¤„ç†å¤±è´¥ â†’ {str(e)[:100]}")
        return False


def get_total_cases():
    """æå‰ç»Ÿè®¡æ€»æ¡ˆä¾‹æ•°ï¼ˆè§£å†³è¿›åº¦æ˜¾ç¤ºé—®é¢˜ï¼‰"""
    total = 0
    for subject in SUBJECTS:
        subj_source_dir = os.path.join(SOURCE_DIR, subject)
        if not check_path(subj_source_dir, "dir"):
            continue
        run_dirs = [d for d in os.listdir(subj_source_dir) if
                    check_path(os.path.join(subj_source_dir, d), "dir") and d.startswith("run-")]
        total += len(run_dirs) * len(STATES)
    return total


# ===================== æ‰¹é‡è¿è¡Œä¸»é€»è¾‘ï¼ˆæ•´åˆä¼˜åŒ–ï¼‰ =====================
if __name__ == "__main__":
    print("=" * 80)
    print("å¼€å§‹æ‰¹é‡å¤„ç†ä¸˜è„‘-çš®å±‚å¶æå­CCGåˆ†æï¼ˆä¸­å’Œç‰ˆï¼‰")
    print(f"è¢«è¯•åˆ—è¡¨ï¼š{SUBJECTS} | çŠ¶æ€ï¼š{STATES} | ç»“æœä¿å­˜ç›®å½•ï¼š{SAVE_DIR}")
    print("=" * 80)

    # æå‰ç»Ÿè®¡æ€»æ¡ˆä¾‹æ•°ï¼ˆè§£å†³è¿›åº¦æ˜¾ç¤º?çš„é—®é¢˜ï¼‰
    TOTAL_CASES = get_total_cases()
    processed_cases = 0
    success_cases = 0

    for subject in SUBJECTS:
        print(f"\n{'=' * 60}\nå¤„ç†è¢«è¯•ï¼š{subject}\n{'=' * 60}")

        # 1. åŠ è½½æ··åˆæºç©ºé—´ï¼ˆæ¯ä¸ªè¢«è¯•ä»…åŠ è½½1æ¬¡ï¼‰
        bem_dir = os.path.join(FREESURFER_DIR, subject, "bem")
        mixed_src_fname = os.path.join(bem_dir, f"{subject}-mixed-src.fif")
        if not check_path(mixed_src_fname):
            print(f"âŒ {subject} æ··åˆæºç©ºé—´ç¼ºå¤± â†’ è·³è¿‡è¯¥è¢«è¯•")
            continue
        src = mne.read_source_spaces(mixed_src_fname)
        print(f"âœ… åŠ è½½{subject}æ··åˆæºç©ºé—´å®Œæˆ")

        # 2. è‡ªåŠ¨è¯»å–å½“å‰è¢«è¯•çš„runç›®å½•
        subj_source_dir = os.path.join(SOURCE_DIR, subject)
        if not check_path(subj_source_dir, "dir"):
            print(f"âŒ {subject} æ— STCæ•°æ®ç›®å½• â†’ è·³è¿‡")
            continue
        run_dirs = sorted([d for d in os.listdir(subj_source_dir)
                           if check_path(os.path.join(subj_source_dir, d), "dir") and d.startswith("run-")])
        if not run_dirs:
            print(f"âŒ {subject} æ— æœ‰æ•ˆrunç›®å½• â†’ è·³è¿‡")
            continue
        print(f"âœ… {subject} æ£€æµ‹åˆ°æœ‰æ•ˆrunï¼š{run_dirs}")

        # 3. éå†runå’ŒçŠ¶æ€
        for run in run_dirs:
            for state in STATES:
                processed_cases += 1
                print(f"\n[{processed_cases}/{TOTAL_CASES}] å¤„ç†ï¼š{subject}-{run}-{state}")
                if process_single_case(subject, run, state, src):
                    success_cases += 1

        # é‡Šæ”¾å½“å‰è¢«è¯•çš„srcå†…å­˜
        del src

    # æ‰¹é‡å¤„ç†æ€»ç»“
    print("\n" + "=" * 80)
    print(f"æ‰¹é‡å¤„ç†å®Œæˆ | æ€»æ¡ˆä¾‹æ•°ï¼š{TOTAL_CASES} | æˆåŠŸæ•°ï¼š{success_cases} | å¤±è´¥æ•°ï¼š{TOTAL_CASES - success_cases}")
    print(f"æˆåŠŸç‡ï¼š{success_cases / TOTAL_CASES * 100:.1f}%" if TOTAL_CASES > 0 else "æ— æ¡ˆä¾‹å¤„ç†")
    print("=" * 80)